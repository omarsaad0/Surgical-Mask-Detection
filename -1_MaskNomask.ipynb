{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "#import serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining 'VideoCapture' object\n",
    "# and reading stream video from camera\n",
    "camera = cv2.VideoCapture(0)\n",
    "camera = cv2.VideoCapture(0)\n",
    "#ser = serial.Serial()\n",
    "#ser.baudrate = 9600\n",
    "#ser.port = 'COM4'\n",
    "#ser.open()\n",
    "# Preparing variables for spatial dimensions of the frames\n",
    "h, w = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:\\Education\\Courses\\ComputerVision\\YOLO-3-OpenCV\\CUSTOM_DATA_FOR_PROJECT_1\\Trained_Weights\\masknomask/obj.names') as f:\n",
    "    # Getting labels reading every line\n",
    "    # and putting them into the list\n",
    "    labels = [line.strip() for line in f]\n",
    "network = cv2.dnn.readNetFromDarknet(\n",
    "    r'D:\\Education\\Courses\\ComputerVision\\YOLO-3-OpenCV\\CUSTOM_DATA_FOR_PROJECT_1\\Trained_Weights\\masknomask/yolov4-tiny-obj2.cfg',\n",
    "    r'D:\\Education\\Courses\\ComputerVision\\YOLO-3-OpenCV\\CUSTOM_DATA_FOR_PROJECT_1\\Trained_Weights\\masknomask/yolov4-tiny-obj2_best.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_names_all = network.getLayerNames()\n",
    "layers_names_output = \\\n",
    "    [layers_names_all[i[0] - 1] for i in network.getUnconnectedOutLayers()]\n",
    "probability_minimum = 0.4\n",
    "threshold = 0.4\n",
    "colours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Capturing frame-by-frame from camera\n",
    "    _, frame = camera.read()\n",
    "\n",
    "    # Getting spatial dimensions of the frame\n",
    "    # we do it only once from the very beginning\n",
    "    # all other frames have the same dimension\n",
    "    if w is None or h is None:\n",
    "        # Slicing from tuple only first two elements\n",
    "        h, w = frame.shape[:2]\n",
    "    # blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size, mean, swapRB=True)\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\n",
    "                                 swapRB=True, crop=False)\n",
    "    network.setInput(blob)  # setting blob as input to the network\n",
    "    start = time.time()\n",
    "    output_from_network = network.forward(layers_names_output)\n",
    "    end = time.time()\n",
    "    # Showing spent time for single current frame\n",
    "    #print('Current frame took {:.5f} seconds'.format(end - start))\n",
    "    # Preparing lists for detected bounding boxes,\n",
    "    # obtained confidences and class's number\n",
    "    bounding_boxes = []\n",
    "    confidences = []\n",
    "    class_numbers = []\n",
    "    for result in output_from_network:\n",
    "        # Going through all detections from current output layer\n",
    "        for detected_objects in result:\n",
    "            # Getting 80 classes' probabilities for current detected object\n",
    "            scores = detected_objects[5:]\n",
    "            # Getting index of the class with the maximum value of probability\n",
    "            class_current = np.argmax(scores)\n",
    "            # Getting value of probability for defined class\n",
    "            confidence_current = scores[class_current]\n",
    "            # Eliminating weak predictions with minimum probability\n",
    "            if confidence_current > probability_minimum:   \n",
    "                \n",
    "                box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
    "\n",
    "                # Now, from YOLO data format, we can get top left corner coordinates\n",
    "                # that are x_min and y_min\n",
    "                x_center, y_center, box_width, box_height = box_current\n",
    "                x_min = int(x_center - (box_width / 2))\n",
    "                y_min = int(y_center - (box_height / 2))\n",
    "\n",
    "                # Adding results into prepared lists\n",
    "                bounding_boxes.append([x_min, y_min,\n",
    "                                       int(box_width), int(box_height)])\n",
    "                confidences.append(float(confidence_current))\n",
    "                class_numbers.append(class_current)\n",
    "                ######################################################\n",
    "    results = cv2.dnn.NMSBoxes(bounding_boxes, confidences,\n",
    "                               probability_minimum, threshold) \n",
    "    if len(results) > 0:\n",
    "        # Going through indexes of results\n",
    "        for i in results.flatten():\n",
    "            # Getting current bounding box coordinates,\n",
    "            # its width and height\n",
    "            x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "            box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "\n",
    "            # Preparing colour for current bounding box\n",
    "            # and converting from numpy array to list\n",
    "            colour_box_current = colours[class_numbers[i]].tolist()\n",
    "\n",
    "            # # # Check point\n",
    "            # print(type(colour_box_current))  # <class 'list'>\n",
    "            # print(colour_box_current)  # [172 , 10, 127]\n",
    "            #frame[x_min:x_min + box_width,y_min:y_min + box_height] = cv2.GaussianBlur(frame[x_min:x_min + box_width,y_min:y_min + box_height], (21,21), cv2.BORDER_DEFAULT)\n",
    "            # Drawing bounding box on the original current frame\n",
    "            cv2.rectangle(frame, (x_min, y_min),\n",
    "                          (x_min + box_width, y_min + box_height),\n",
    "                          colour_box_current, 2)\n",
    "            try:\n",
    "                #frame[y_min:y_min + box_height,x_min:x_min + box_width] = cv2.GaussianBlur(frame[y_min:y_min + box_height,x_min:x_min + box_width], (51,51), cv2.BORDER_DEFAULT)\n",
    "                frame[y_min:y_min + box_height,x_min:x_min + box_width] = cv2.blur(frame[y_min:y_min + box_height,x_min:x_min + box_width], (25,25))\n",
    "                # Preparing text with label and confidence for current bounding box\n",
    "                text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])],\n",
    "                                                       confidences[i])\n",
    "                #print(\"Object: \",text_box_current,x_min,y_min,box_height,box_width)\n",
    "                # Putting text with label and confidence on the original image\n",
    "                cv2.putText(frame, text_box_current, (x_min, y_min - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, colour_box_current, 4)\n",
    "            except:\n",
    "                text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])],\n",
    "                                                   confidences[i])\n",
    "                #print(\"Object: \",text_box_current,x_min,y_min,box_height,box_width)\n",
    "                # Putting text with label and confidence on the original image\n",
    "                cv2.putText(frame, text_box_current, (x_min, y_min - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, colour_box_current, 4)\n",
    "    # Showing results obtained from camera in Real Time\n",
    "\n",
    "    # Showing current frame with detected objects\n",
    "    # Giving name to the window with current frame\n",
    "    # And specifying that window is resizable\n",
    "    cv2.namedWindow('Mask Detection YOLOv4Tiny', cv2.WINDOW_NORMAL)\n",
    "    # Pay attention! 'cv2.imshow' takes images in BGR format\n",
    "    cv2.imshow('Mask Detection YOLOv4Tiny', frame)\n",
    "\n",
    "    # Breaking the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Releasing camera\n",
    "camera.release()\n",
    "# Destroying all opened OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
